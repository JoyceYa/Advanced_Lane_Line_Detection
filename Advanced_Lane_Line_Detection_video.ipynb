{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import deque\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define the calibration function\n",
    "def get_camera_calibration(calib_file):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,9,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    imgpoints = []\n",
    "    objpoints = []\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(calib_file)\n",
    "    # Step through the list and search for chessboard corners\n",
    "    img_calib_show = []\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)        \n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            img_calib_show.append(img) # for visualization    \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "            \n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: do the calibration using the images for calibration.\n",
    "global mtx\n",
    "global dist\n",
    "mtx, dist = get_camera_calibration('./camera_cal/calibration*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define functions for the detection\n",
    "#====================camera_distortion_correction===================================\n",
    "def camera_distortion_correction(img, mtx, dist):      \n",
    "    # Undistort using mtx and dist\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)        \n",
    "    return undist\n",
    "#===================thresholded_binary====================================\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1    \n",
    "    return binary_output\n",
    "\n",
    "def abs_sobel_thresh(img,sobel_kernel=3, orient='x',thresh=(0,255)):\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F,1,0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F,0,1, ksize=sobel_kernel)\n",
    "    if orient=='x':\n",
    "        sobel = sobelx\n",
    "    elif orient=='y':\n",
    "        sobel = sobely\n",
    "    else:\n",
    "        sobel = np.sqrt(np.square(sobelx)+np.square(sobely))\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    sobel_scaled = np.uint8(255*sobel_abs/np.max(sobel_abs))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "    binary_output = np.zeros_like(sobel_scaled)\n",
    "    binary_output[(sobel_scaled >= thresh[0]) & (sobel_scaled <= thresh[1])] = 1   \n",
    "    return binary_output\n",
    "\n",
    "def hls_select(img, s_thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel > s_thresh[0]) & (s_channel <= s_thresh[1])] = 1    \n",
    "    return binary_output\n",
    "\n",
    "def thresholded_binary(img,ksize = 5):        \n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(40, 100))\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(0, 255))\n",
    "    gradxy = abs_sobel_thresh(img, orient='xy', sobel_kernel=ksize, thresh=(30, 100))\n",
    "    dir_binary = dir_threshold(img, sobel_kernel=15, thresh=(0.8, 1.3))\n",
    "    s_binary = hls_select(img, s_thresh=(180, 255))\n",
    "    \n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((gradxy == 1) & (dir_binary == 1)) | (s_binary == 1)] = 1     \n",
    "    return combined\n",
    "#================birds-eye view transfer=======================================\n",
    "def birds_eye_transfer(img,flag=1):\n",
    "    '''\n",
    "    img: binary image\n",
    "    '''\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    offset = 90\n",
    "    src = np.float32([[559,477],[280,680],[1035,680],[728,477]])\n",
    "    dst = np.float32([[280+offset,330],[280+offset,680],[1035-offset,680],[1035-offset,330]])\n",
    "    if flag==1:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "    elif flag==2:\n",
    "        M = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(img, M, img_size)    \n",
    "    return warped\n",
    "\n",
    "def region_of_interest(img):\n",
    "    '''\n",
    "    img: binary image\n",
    "    '''\n",
    "    shape = img.shape \n",
    "    vertices = np.array([[(90,shape[0]),(shape[1]-90,shape[0]),(shape[1]-570,420),(570,420)]],dtype=np.int32)\n",
    "    mask = np.zeros_like(img)   \n",
    "    ignore_mask_color = 255        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "#================get line inds & pixels=======================================\n",
    "def get_line_inds(img,linex_base,nwindows=9,margin=70,minpix = 50):    \n",
    "    window_height = np.int(img.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    linex_current = linex_base\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    line_inds = []    \n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_x_low = linex_current - margin\n",
    "        win_x_high = linex_current + margin\n",
    "        if linex_base<img.shape[1]/2:\n",
    "            good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_x_low) &  (nonzerox < win_x_high)).nonzero()[0]\n",
    "        else:\n",
    "            good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_x_low) &  (nonzerox < win_x_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        line_inds.append(good_inds)       \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_inds) > minpix:\n",
    "            linex_current = np.int(np.mean(nonzerox[good_inds]))                   \n",
    "    # Concatenate the arrays of indices\n",
    "    line_inds = np.concatenate(line_inds)              \n",
    "    return line_inds\n",
    "\n",
    "def pixels_on_lane(line,lane_inds):    \n",
    "    line_fit = line.avg_fit_coeffs #######avg       \n",
    "    ploty = line.fit_yvals\n",
    "    line_fitx = line_fit[0]*ploty**2 + line_fit[1]*ploty + line_fit[2]        \n",
    "    return line_fitx\n",
    "#================line detection quality check=======================================\n",
    "## done by Line.line_check()\n",
    "#================show boundaries=======================================\n",
    "def show_boundaries(img_orig,img_perspective_trans,left_fitx,right_fitx,ploty):\n",
    "    warp_zero = np.zeros((img_perspective_trans.shape[0],img_perspective_trans.shape[1])).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "        \n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp = birds_eye_transfer(color_warp,flag=2) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img_orig, 1.0, newwarp, 0.6, 0)\n",
    "    \n",
    "    return result\n",
    "#================visual display=======================================\n",
    "def visual_display(img,video,curverad,offset):\n",
    "    if video:\n",
    "        # Add text information on the video frame\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text_pos = 'Pos of the car: '+str(np.round(offset*100))+ ' cm'+'(+ right)'        \n",
    "        if curverad >= 10000:\n",
    "            radius = 'Inf'\n",
    "        else:\n",
    "            radius = str(curverad)\n",
    "        text_rad = 'Radius: '+radius+ ' m'\n",
    "        cv2.putText(img,text_pos,(10,25), font, 1,(255,255,255),2)\n",
    "        cv2.putText(img,text_rad,(10,75), font, 1,(255,255,255),2)\n",
    "        return img  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2: define the pipeline\n",
    "#================PipeLine=======================================\n",
    "def get_lane_pipeline(img):\n",
    "    \n",
    "    imshape = img.shape    \n",
    "    # Apply a distortion correction to raw images.\n",
    "    img_undist = camera_distortion_correction(img, mtx, dist)\n",
    "    # Create a thresholded binary image.\n",
    "    img_thresholded_binary = thresholded_binary(img_undist,ksize = 5)    \n",
    "    img_thresholded_binary = region_of_interest(img_thresholded_binary)    \n",
    "    # Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "    img_perspective_trans = birds_eye_transfer(img_thresholded_binary,flag=1)\n",
    "    # Detect lane pixels and fit to find the lane boundary.\n",
    "    yval = max(left.fit_yvals)\n",
    "    if left.detected:\n",
    "        left_base = left.line_pos[0]\n",
    "    elif left.n_buffered>0 :\n",
    "        left_base= left.avg_fit_coeffs[0]*yval**2 + left.avg_fit_coeffs[1]*yval + left.avg_fit_coeffs[2]\n",
    "    else:\n",
    "        left_base = imshape[1]*1/4\n",
    "        \n",
    "    if right.detected:\n",
    "        right_base = right.line_pos[1]\n",
    "    elif right.n_buffered>0  :\n",
    "        right_base= right.avg_fit_coeffs[0]*yval**2 + right.avg_fit_coeffs[1]*yval + right.avg_fit_coeffs[2]\n",
    "    else:\n",
    "        right_base = imshape[1]*3/4\n",
    "    \n",
    "    left_lane_inds = get_line_inds(img_perspective_trans,left_base)\n",
    "    right_lane_inds = get_line_inds(img_perspective_trans,right_base)        \n",
    "    left.detected,left.n_buffered = left.update(img_perspective_trans,left_lane_inds,left_base)\n",
    "    right.detected,right.n_buffered = right.update(img_perspective_trans,right_lane_inds,right_base)\n",
    "    # Determine the curvature of the lane and vehicle position with respect to center.    \n",
    "    curvarad = np.round(left.radius_of_curvature+right.radius_of_curvature)/2    \n",
    "    offset = (np.abs(left.line_offset)-np.abs(right.line_offset))/2\n",
    "    # Warp the detected lane boundaries back onto the original image.\n",
    "    left_fitx = pixels_on_lane(left,left_lane_inds)\n",
    "    right_fitx = pixels_on_lane(right,right_lane_inds)\n",
    "    masked_img = show_boundaries(img_undist,img_perspective_trans,left_fitx,right_fitx,left.fit_yvals)\n",
    "    # Output visual display.\n",
    "    final_img = visual_display(masked_img,1,curvarad,offset)\n",
    "    \n",
    "    return final_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define a class to receive the characteristics of each line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line:\n",
    "    def __init__(self,n=5):\n",
    "        # length of queue to store data\n",
    "        self.n = n\n",
    "        #number of fits in buffer\n",
    "        self.n_buffered = 0\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False          \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = deque([],maxlen=n)\n",
    "        # xvals of the most recent fit\n",
    "        self.current_fit_xvals = [np.array([False])]          \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.avgx = None       \n",
    "        # x diff\n",
    "        self.x_diff = 0\n",
    "        \n",
    "        # fit coeffs of the last n fits\n",
    "        self.recent_fit_coeffs = deque([],maxlen=n)\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit_coeffs = [np.array([False])]    \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.avg_fit_coeffs = None  \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float')         \n",
    "              \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        #y values for line fit\n",
    "        self.fit_yvals = np.linspace(0, 100, num=101)*7.2  # always the same y-range as image\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = 10000 \n",
    "        self.recent_curvatures = deque([],maxlen=n)\n",
    "        self.avg_curvature = None\n",
    "        # origin (pixels) of fitted line at the bottom of the image\n",
    "        self.line_pos = np.array([320,960])         \n",
    "        self.current_fit_base = None        \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_offset = None         \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float')     \n",
    "    \n",
    "    def set_current_fit_xvals(self):\n",
    "        '''\n",
    "        Get x coordinates of fitted points in the current frame \n",
    "        '''\n",
    "        yvals = self.fit_yvals\n",
    "        yval = max(yvals)\n",
    "        self.current_fit_xvals = self.current_fit_coeffs[0]*yvals**2 + self.current_fit_coeffs[1]*yvals + self.current_fit_coeffs[2]\n",
    "        self.current_fit_base = self.current_fit_coeffs[0]*yval**2 + self.current_fit_coeffs[1]*yval + self.current_fit_coeffs[2]\n",
    "    \n",
    "    def add_data(self):\n",
    "        '''\n",
    "        Add new fitting information of current frames into the buffer\n",
    "        '''\n",
    "        self.recent_xfitted.appendleft(self.current_fit_xvals)\n",
    "        self.recent_fit_coeffs.appendleft(self.current_fit_coeffs)\n",
    "        ##\n",
    "        self.recent_curvatures.appendleft(self.radius_of_curvature)\n",
    "        assert len(self.recent_xfitted)==len(self.recent_fit_coeffs)\n",
    "        self.n_buffered = len(self.recent_xfitted)\n",
    "        \n",
    "    def pop_data(self):   \n",
    "        '''\n",
    "        Delete the fitting information of frames that fails to detect lines\n",
    "        '''\n",
    "        if self.n_buffered>0:\n",
    "            self.recent_xfitted.pop()\n",
    "            self.recent_fit_coeffs.pop()\n",
    "            ##\n",
    "            self.recent_curvatures.pop()\n",
    "            assert len(self.recent_xfitted)==len(self.recent_fit_coeffs)\n",
    "            self.n_buffered = len(self.recent_xfitted)\n",
    "        \n",
    "        return self.n_buffered\n",
    "    \n",
    "    def set_avgx(self):\n",
    "        '''\n",
    "        Get the average x coordinates of fitted points \n",
    "        '''\n",
    "        fits = self.recent_xfitted\n",
    "        if len(fits)>0:\n",
    "            avg=0\n",
    "            for fit in fits:\n",
    "                avg +=np.array(fit)\n",
    "            avg = avg / len(fits)\n",
    "            self.avgx = avg\n",
    "    \n",
    "    def set_avgcoeffs(self):\n",
    "        '''\n",
    "        Average the fit coefficents to improve robustness\n",
    "        '''\n",
    "        coeffs = self.recent_fit_coeffs\n",
    "        if len(coeffs)>0:\n",
    "            avg=0\n",
    "            for coeff in coeffs:\n",
    "                avg +=np.array(coeff)\n",
    "            avg = avg / len(coeffs)\n",
    "            self.avg_fit_coeffs = avg\n",
    "            \n",
    "    def set_avg_curvature(self):\n",
    "        '''\n",
    "        Average the fit coefficents to improve robustness\n",
    "        '''\n",
    "        curs = self.recent_curvatures\n",
    "        if len(curs)>0:\n",
    "            avg=0\n",
    "            for cur in curs:\n",
    "                avg +=np.array(cur)\n",
    "            avg = avg / len(curs)\n",
    "            self.avg_curvature = avg\n",
    "    \n",
    "    def set_allxy(self,img,lane_inds):\n",
    "        '''\n",
    "        Get the coordinates of points in search windows\n",
    "        '''\n",
    "        nonzero = img.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        self.allx = nonzerox[lane_inds]\n",
    "        self.ally = nonzeroy[lane_inds] \n",
    "        \n",
    "    def set_current_fit_coeffs(self):\n",
    "        '''\n",
    "        Get the fit coefficents of the line in current image\n",
    "        '''\n",
    "        self.current_fit_coeffs = np.polyfit(self.ally, self.allx, 2)        \n",
    "    \n",
    "    def set_radius_of_curvature(self):\n",
    "        '''\n",
    "        Get the curvature of the line in real world\n",
    "        '''\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        y_eval = max(self.fit_yvals)        \n",
    "        if self.avg_fit_coeffs is not None:\n",
    "            avg_fitx = self.avg_fit_coeffs[0]*self.fit_yvals**2 + self.avg_fit_coeffs[1]*self.fit_yvals + self.avg_fit_coeffs[2]                \n",
    "            avg_fit_cr = np.polyfit(self.fit_yvals*ym_per_pix, avg_fitx*xm_per_pix, 2)\n",
    "            self.radius_of_curvature = ((1 + (2*avg_fit_cr[0]*y_eval*ym_per_pix + avg_fit_cr[1])**2)**1.5) / np.absolute(2*avg_fit_cr[0])\n",
    "        else:\n",
    "            cur_fitx = self.current_fit_coeffs[0]*self.fit_yvals**2 + self.current_fit_coeffs[1]*self.fit_yvals + self.current_fit_coeffs[2]                \n",
    "            cur_fit_cr = np.polyfit(self.fit_yvals*ym_per_pix, cur_fitx*xm_per_pix, 2)\n",
    "            self.radius_of_curvature = ((1 + (2*cur_fit_cr[0]*y_eval*ym_per_pix + cur_fit_cr[1])**2)**1.5) / np.absolute(2*cur_fit_cr[0])\n",
    "        return self.radius_of_curvature           \n",
    "    def set_line_pos(self,img):\n",
    "        '''\n",
    "        Use histogram to get the two base point of the lines\n",
    "        '''\n",
    "        histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "        midpoint = np.int(histogram.shape[0]//2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "        self.line_pos = [leftx_base,rightx_base]        \n",
    "        \n",
    "    def set_line_offset(self,line_base):\n",
    "        '''\n",
    "        To get the distance(m) between car center and the line's down points\n",
    "        '''\n",
    "        if line_base<640:\n",
    "            self.line_offset = (self.line_pos[0] - 640)*3.7/700.0 \n",
    "        else:\n",
    "            self.line_offset = (self.line_pos[1] - 640)*3.7/700.0 \n",
    "   \n",
    "    def set_x_diff(self,line_base):\n",
    "        '''\n",
    "        To get the different between current x coordinate and average x coordinate of the line's down point \n",
    "        '''\n",
    "        if(self.n_buffered > 0):\n",
    "            yval = max(self.fit_yvals)\n",
    "            avg_x = self.avg_fit_coeffs[0]*yval**2 + self.avg_fit_coeffs[1]*yval + self.avg_fit_coeffs[2]\n",
    "            current_x = line_base\n",
    "            self.x_diff = current_x-avg_x      \n",
    "           \n",
    "    def line_check(self):\n",
    "        '''\n",
    "        Use line_offset & x_diff to check whether the detected result counts.\n",
    "        '''\n",
    "        flag = True\n",
    "        maxdist = 2.3  # distance in meters from the lane\n",
    "        maxxdiff = 90        \n",
    "        max_base = 675        \n",
    "        max_base_diff = 95        \n",
    "        #max_cur_diff = 200\n",
    "        \n",
    "        base_diff = [abs(self.line_pos[0]-self.current_fit_base),abs(self.line_pos[1]-self.current_fit_base)]\n",
    "                \n",
    "        if(abs(self.line_offset) > maxdist ):\n",
    "            print('lane offsets too much',self.line_offset)\n",
    "            flag  = False  \n",
    "        \n",
    "        if(min(base_diff) > max_base_diff ):\n",
    "            print('base differs too much',min(base_diff))\n",
    "            flag  = False          \n",
    "       \n",
    "        if(self.n_buffered > 0):\n",
    "            if self.x_diff>maxxdiff:\n",
    "                print('x differs too much',self.x_diff)\n",
    "                flag=False \n",
    "            '''\n",
    "            cur_diff = abs(self.avg_curvature-self.radius_of_curvature)\n",
    "            if(cur_diff> max_cur_diff ):\n",
    "                print('Curvature differs too much',cur_diff)\n",
    "                flag  = False\n",
    "            '''        \n",
    "        if (abs(self.line_pos[0]-self.line_pos[1])>max_base):\n",
    "            print('lane width too large',abs(self.line_pos[0]-self.line_pos[1]))\n",
    "            flag  = False\n",
    "        \n",
    "        return flag    \n",
    "        \n",
    "    def update(self,img,lane_inds,line_base):\n",
    "        '''\n",
    "        Fit the current image and determine if the detected result is good enough to put into the buffer.\n",
    "        '''        \n",
    "        self.set_allxy(img,lane_inds)\n",
    "        self.set_current_fit_coeffs()\n",
    "        self.set_current_fit_xvals()\n",
    "        self.set_radius_of_curvature()\n",
    "        self.set_line_pos(img)\n",
    "        self.set_line_offset(line_base)\n",
    "        self.set_x_diff(line_base)       \n",
    "        if self.line_check():\n",
    "            self.detected=True\n",
    "            self.add_data()\n",
    "            self.set_avgx()\n",
    "            self.set_avgcoeffs()  \n",
    "            self.set_avg_curvature()\n",
    "        else:\n",
    "            self.detected=False            \n",
    "            self.pop_data()            \n",
    "            if self.n_buffered>0:\n",
    "                self.set_avgx()\n",
    "                self.set_avgcoeffs()  \n",
    "                self.set_avg_curvature()\n",
    "                    \n",
    "        return self.detected,self.n_buffered     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Detect lane lines in the project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/processed_project_video1.mp4\n",
      "[MoviePy] Writing video test_videos_output/processed_project_video1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▏                                           | 561/1261 [02:54<03:25,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane width too large 678\n",
      "lane width too large 678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████▏                                           | 562/1261 [02:54<03:29,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane width too large 682\n",
      "lane width too large 682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████                | 1003/1261 [05:10<01:17,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane width too large 695\n",
      "lane width too large 695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████                | 1004/1261 [05:11<01:22,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane width too large 690\n",
      "lane width too large 690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████▎              | 1023/1261 [05:17<01:11,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane width too large 682\n",
      "lane width too large 682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|███████████████████████████████████████████████████████████████▎              | 1024/1261 [05:17<01:12,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane width too large 685\n",
      "lane width too large 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████▌            | 1059/1261 [05:28<01:03,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x differs too much 91.591679614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████▋            | 1061/1261 [05:29<01:02,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x differs too much 111.6419149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [06:34<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/processed_project_video1.mp4 \n",
      "\n",
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "global left\n",
    "global right\n",
    "\n",
    "left = Line(9)\n",
    "right = Line(9)\n",
    "output = 'test_videos_output/processed_project_video1.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "out_clip = clip.fl_image(get_lane_pipeline)\n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
